---
title: 目标检测
tags: 新建,模板,小书匠
grammar_cjkRuby: true
---


## 目的

> 要干什么事情

![enter description here](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536067501454.png)

image classification：识别图片的类别
classification localization：找出目标在图片中的位置，单个目标（有可能是不同的种类），主要是识别和定位
target Detection：多个对象在单张图片中的位置


## 输出的编码

![输出的编码](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536067955898.png)

在分类的基础上再增加几个参数

如假设分类的输出$y\_ = ({y_1},{y_2},{y_3},{y_4})$，${y_1},{y_2},{y_3},{y_4}$分别表示不同的种类，在做目标定位时在此基础上再添加四个参数$y'\_ = ({y_1},{y_2},{y_3},{y_4},{y_5},{y_6},{y_7},{y_8})$后面的四个分别用来表示${b_x},{b_y},{b_w},{b_h}$，分别为矩形中点位置，矩形的宽度和高度，一般用归一化的表示。

下图表示了输出的编码

![输出的编码](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536068899502.png)

对比与遗传算法
==遗传算法==的编码意图用较少的位数表达较多的信息，可以理解成稠密编码，在遗传算法中这样的好处是减少了搜索空间
==神经网络==要寻找的是一个映射，搜索空间对于神经网络不再显的重要（梯度就决定了收敛方向），所以越简单越容易映射，编码空间的大小，即使很多的编码没有意义也无所谓


## 优化目标

如图所示，最简单的就是平方误差，

> 个人认为这样不好，这里输出的每个元素不是同一层级的，不同层次的元素用不同的误差

![平方误差](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536069257246.png)

后面讲了  
1. positon可以用均方差  
2. $p_c$用logisti function  
3. $c_i$ 用softmax 确实这样才比较合适

## 特征点的识别
landmark
前面识别的矩形边框其实可以理解成，识别了矩形边框的四个点，那么更进一步，可以识别更多的特征点，这种就叫做特征点的识别，这种场景输出的就是多个点的位置。

![特征点的识别](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536069891969.png)

使用的场景AR相机，头上画个啥东西，现在已经很成熟了 （微信的圣诞帽，sipchat）

## 基于滑动窗口的目标检测算法

sliding windows

剪切图片使目标居于中心。然后用卷积网络进行训练
![窗口训练](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536070959646.png)

训练好了之后，选定窗口大小，将图片中的每个窗口放到卷积网络中判断是否包含目标，如下图所示
滑动需要选择合适的stride类似于卷积过程中的stride

![窗口滑动示意](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536071240540.png)

调整窗口大小

![调整窗口大小](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536071379398.png)

**方法评价**
1. stride小计算成本高，尤其是卷积网络中
2. stride窗口少，检测的不准，性能可能会差


这个方法还有一些问题，一张图片中肯定会有多个窗口检测到同一个目标，那么选取哪一个窗口作为矩形边框？另外如何判断不同的窗口检测到的是不是同一个目标（可能会有多个目标）

## 卷积的滑动窗口实现
论文： overfeat：integral recognition localization and detection using convolutional networks


全连接层转换成卷积层
![全连接层转换成卷积层](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536073308941.png)

一个滑动窗口在计算上面有很多重复的地方，通过算法不需要一个个窗口的计算，而是计算整个图片，这样共享了大量的运算。下图是示意图，同样脑子里面想一下公式就能够证明。


![的](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536073813330.png)

![示意图](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536074393907.png)



当然前面提到的问题依然没有得到解决，多个窗口同时检测到


## bounding box 预测

papper：you only look once real time object detection

提出背景，在滑动窗口不密集的情况下，使用滑动窗口得到的边框不够准确，使用bounding box 预测能够得到更精确的边框。使用yolo算法

![enter description here](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536146775467.png)

这里要提出疑问了，下图中的拆分好像和前面提到的滑动窗口无关，在每个分割的窗口不是用的滑动窗口的卷积算法

![yolo 算法](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536146895675.png)

1. 图片分割
2. 对每个小图片使用目标定位算法

![yolo](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536147189538.png)

输出的结构

![输出向量](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536147407570.png)

当网格取得很细的时候多个目标落在一个分割区域中的概率很低，使用该算法不需要考虑滑动窗口大小和滑动的stride，优点和前面的滑动一样，整张图片只需要进行一个卷积算法


编码，当然在论文中还有很多的算法来保证参数的范围，（猜测是通过激活函数，映射到目标区间内）


![编码](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536148138922.png)

疑问：这种的训练集的标签要怎么打，猜测是人工画边框，图像处理识别红色的边框然后对y进行编码

## 目标检测算法的优劣判断

intersection over union（交并比函数）

很简单一般就是计算交集和并集的比，一般约定lou>0.5就是可以接受的了

![iou](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536153758000.png)

## 非极大值抑制

在滑动窗口或者yolo中一个对象可能被检测多次，非极大值抑制会尽量保证每个对象只检测一次，如下图所示

![一个对象被检测多次](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536154311853.png)

算法步骤如下：
 
 ![算法步骤](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536155672238.png)
 
 如果有多种类别的目标那就对，每种目标单独做一次非极大值抑制算法。
 
 ## Anchor Boxes
 在一个栅格中包含多个目标的处理方法，提升维度编码。总感觉有点问题，这样编码的话还需要c1，c2，c3吗
 
 ![编码](https://hosbimkimg.oss-cn-beijing.aliyuncs.com/小书匠/1536158177200.png)
 
 可以选择多个anchor box 来选取不同的种类
 
 ## yolo
 将前面的全部组合起来
 
 努力无法撑起自己的梦想，真正的不甘现状，就是在行动上最大化的利用时间，走出舒适区去战斗，只要敢做就就有无限的可能。不要在你30岁时，做一个只会玩手机的胖子。逼自己成为一个不一样的人。
 愿你出走半生，归来时任是少年
 
 ## fast-rcnn
 选取一些窗口，运行卷积神经网络，尽量不在无关的图片进行
 用分割算法
 region，slow
 fast R-CNN
 Faster R-CNN
 
 这个是需要看论文的
 
 